---
title: Implement the core agent loop
description: This tutorial teaches you how to implement the core agent loop from scratch.
---

import { Aside, Card, Steps } from '@astrojs/starlight/components';

In this lab, we'll implement the core agent loop from scratch. The agent loop
is the heart of any agent application. It is responsible for receiving user
input, sending it to the language model, handling tool calls, and returning
the final output to the user.

## Lab files

- **Starter:** [labs/agent-loop/001-setup-application][LAB_START_SOURCE]
- **Solution:** [labs/agent-loop/002-main-agent-loop][LAB_SOLUTION_SOURCE]

## What is an agent loop?

Let's first explore what an agent loop is. An agent loop is a continuous process that
allows an AI agent to interact with its environment, make decisions, and perform
actions based on the input it receives.

The agent loop shows similarities to how chat bots like ChatGPT work. Let's explore
this first, and then look at how we can extend this to build an agent loop.

Remember how an LLM can generate a response based on input. Modern LLMs are
trained as chat bots, which means they are designed to handle multi-turn
conversations with users. In fact, there's no other way to talk to an LLM 
than through a conversation.

When you build a chatbot, you typically send a prompt to the server as part of
the conversation and then display the response to the user.

You can extend this behavior by introducing tools. When you submit a user prompt,
you can include a list of tools the LLM can use to answer the prompt. The 
LLM will then decide whether it can answer the prompt directly or if it needs
to use one of the tools. If it decides to use a tool, it will generate a
special response of type `tool_call` and return it to the client.

It's up to you, as a developer, to detect the `tool_call` response, execute
the tool mentioned in the response, and send the result of the tool execution
back to the LLM. The LLM will then continue processing the conversation, now
with the result of the tool execution included. This process can repeat
multiple times, with the LLM deciding to use more tools as needed, until it
generates a final answer.

The use of tools is what turns a chat bot interaction loop into an agent loop. 
Depending on what you want to do with your agent, you're going to need different tools
as we'll learn in later modules.

For now, let's start by building the agent loop itself.

## Create the application entrypoint

Start by modifying the `Program.cs` in the `CodingAgent` project.
Add the following code to the end of the file:

```csharp title="Program.cs" ins={18-37}
using Microsoft.Extensions.Configuration;
using Microsoft.SemanticKernel;
using CodingAgent;
using Spectre.Console;

var configuration = new ConfigurationBuilder()
    .AddUserSecrets(typeof(Program).Assembly)
    .AddEnvironmentVariables()
    .Build();

var kernelBuilder = Kernel.CreateBuilder()
    .AddAzureOpenAIChatCompletion(
        configuration["LanguageModel:DeploymentName"]!,
        configuration["LanguageModel:Endpoint"]!,
        configuration["LanguageModel:ApiKey"]!
    );

var kernel = kernelBuilder.Build();
var agent = new Agent(kernel);

AnsiConsole.Write(new Markup("[green]CODING AGENT[/]\n"));
AnsiConsole.Write(new Rule());

while (true)
{
    var prompt = AnsiConsole.Prompt(new TextPrompt<string>(">"));
    var callbacks = new ConsoleCallbacks();

    // Stop the application when the user enters /exit or /quit.
    if (string.Compare(prompt, "/exit", StringComparison.OrdinalIgnoreCase) == 0 ||
        string.Compare(prompt, "/quit", StringComparison.OrdinalIgnoreCase) == 0)
    {
        break;
    }

    await agent.InvokeAsync(prompt, callbacks);
}
```

Let's go over this code step by step:

1. First, we create a new instance of the `Agent` class. Note that it doesn't
   exist yet, we'll create it after this exercise.
2. Next, we print the header of the application to let the user know what they
   started.
3. Then, we create an endless loop in the application that will ask the user
   for input and then run the agent unless we enter specific commands. We'll
   expand the list of commands as we expand the functionality of the agent.

The user interface will be very basic. You can of course expand this with your
own logic if you like. We'll focus on the `Agent` class. Let's start building
it.

## Build the basic agent skeleton

Before we can start building the agent loop itself, we'll need to create two
components:

<Steps>
1. Create a new interface `IAgentCallbacks` in the `CodingAgent` project that
   will contain the interface used by the agent to send content back to the
   user or ask for additional input.

   ```csharp title="IAgentCallbacks.cs"
   public interface IAgentCallbacks
   {

   }
   ```

2. Create a new class in the `CodingAgent` project called `Agent`.
3. Add the following using statements to the top of the class file:
   
   ```csharp title="Agent.cs"
   using Microsoft.SemanticKernel;
   using Microsoft.SemanticKernel.ChatCompletion;
   using Microsoft.SemanticKernel.Connectors.AzureOpenAI;
   ```

4. Next, add the basic skeleton for the agent. This should include a field
   to store `ChatHistory` and a field to store an instance of the `Kernel`
   we configured in the main application.
  
   ```csharp
   using CodingAgent.Plugins;
   using Microsoft.SemanticKernel;
   using Microsoft.SemanticKernel.ChatCompletion;
   using Microsoft.SemanticKernel.Connectors.AzureOpenAI;

   namespace CodingAgent;

   public class Agent
   {
      private ChatHistory _chatHistory;
      private readonly Kernel _kernel;

      public Agent(Kernel kernel)
      {
         _chatHistory = new ChatHistory();
         _kernel = kernel;
      }
   }
   ```

8. Add a new public method to the `Agent` class with the name `InvokeAsync`. 
   This method must return a `Task` and accept a parameter `prompt` of type 
   `string` and a parameter `callbacks` of type `IAgentCallbacks`. 

   ```csharp title="Agent.cs"
   public async Task InvokeAsync(string prompt, IAgentCallbacks callbacks)
   {

   }
   ```

</Steps>

The `Agent` will serve as the main component where we implement the agent loop
and connect to tools. The `IAgentCallbacks` interface is important as it will
help us report results to the terminal and ask for more user input.

## Implement the InvokeAsync method

Now that we have the skeleton in place, it's time to write the logic
for the `InvokeAsync` method.

<Steps>

1. Add the main loop to the `InvokeAsync` method. We'll use a slightly odd
   looking `while(true)` loop that doesn't make much sense now, but we'll improve
   this situation later.

   ```csharp title="Agent.cs" ins={3-17}
   public async Task InvokeAsync(string prompt, IAgentCallbacks callbacks)
   {
      var iterations = 0;
      var chatCompletionService = _kernel.GetRequiredService<IChatCompletionService>();

      _chatHistory.AddUserMessage(prompt);
      _sharedToolsPlugin.Reset();

      while (true)
      {
         iterations++;

         if (iterations > 25)
         {
               break;
         }
      }
   }
   ```

   In the main agent loop we get an instance of the `IChatCompletionService` to
   communicate with the language model. Remember, we're essentially using a chat
   to communicate with the language model. Remember, we're essentially using a
   chat bot to build a coding agent. 
   
   In Semantic Kernel you can get services like `IChatCompletionService` from
   the kernel by calling `GetRequiredService` on it with the type of service you
   need. The `IChatCompletionService` is available because we configured it in
   the `Program.cs` file when we called the setup code for Azure OpenAI.

   <Aside type="tip">
   The core of Semantic Kernel integrates AI services like the chat
   completion service we've added in the `Program.cs` file and used here. 
   
   There are other AI services you can use like the text embedding generators for
   building semantic representations of content so you can let the agent search
   content based on meaning rather than literal keywords.

   Check out the [Microsoft Docs][SK_SERVICES] to learn more about how AI services
   services work in Semantic Kernel.
   </Aside>

2. In the main loop, invoke the chat completion service to get a response to
   the user prompt. You can use the `GetChatMessageContentAsync` method for this.
   Add the received response to the chat history.

   ```csharp title="Agent.cs" ins={17-25}
   public async Task InvokeAsync(string prompt, IAgentCallbacks callbacks)
   {
      var iterations = 0;
      var chatCompletionService = _kernel.GetRequiredService<IChatCompletionService>();

      _chatHistory.AddUserMessage(prompt);

      while (true)
      {
         iterations++;

         if (iterations > 25)
         {
               break;
         }

         var promptExecutionSettings = new AzureOpenAIPromptExecutionSettings()
         {
               FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(autoInvoke: false),
         };

         var response = await chatCompletionService
               .GetChatMessageContentAsync(_chatHistory, promptExecutionSettings);

         _chatHistory.Add(response);
      }
   }
   ```

   This code uses a set of prompt execution settings. These settings control how the 
   language model and Semantic Kernel behave when getting a response from the language model.

   Semantic Kernel uses `FunctionChoiceBehavior` to control how tools are invoked. You
   can set this setting to `None` to prevent tool calls. You can also set it to `Auto`
   so that all tools are available. For our coding agent, we're going to have to set the
   behavior so that all tools are available, but not invoked. We will handle the
   invocation ourselves.

   After calling the language model, we need to save the response to the chat history.
   This is important for building context so the agent knows what to do next.

3. For the agent to be able to code, we'll need to handle tool calls. Let's add this
   code to the agent loop next.

   ```csharp ins={28-36}
   public async Task InvokeAsync(string prompt, IAgentCallbacks callbacks)
   {
      var iterations = 0;
      var chatCompletionService = _kernel.GetRequiredService<IChatCompletionService>();

      _chatHistory.AddUserMessage(prompt);

      while (true)
      {
         iterations++;

         if (iterations > 10)
         {
               break;
         }

         var promptExecutionSettings = new AzureOpenAIPromptExecutionSettings()
         {
               FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(autoInvoke: false),
         };

         var response = await chatCompletionService
            .GetChatMessageContentAsync(_chatHistory, promptExecutionSettings);

         _chatHistory.Add(response);

         var functionCalls = FunctionCallContent.GetFunctionCalls(response).ToList();

         if (!functionCalls.Any())
         {
            // Stop processing if the model has no more function calls to make.
            break;
         }

         await HandleFunctionCalls(functionCalls);
      }
   }
   ```

4. The `HandleFunctionCalls` method is responsible for calling functions and reporting
   results. We're not going to report results in this lab, but we need to add the function
   calling logic:

   ```csharp
   private async Task HandleFunctionCalls(IEnumerable<FunctionCallContent> functionCalls)
   {
      foreach (var functionCall in functionCalls)
      {
         var output = await functionCall.InvokeAsync(_kernel);
         _chatHistory.Add(output.ToChatMessage());
      }
   }
   ```

   This code will iterate over the function calls detected by the language model and
   execute them one-by-one, reporting the result as a chat message. 

   <Aside type="tip" title="You can simplify tool invocations">

   Semantic Kernel can completely handle tool invocation for you. You can set the
   `FunctionChoiceBehavior` to `Auto(autoInvoke: true)` and the SDK will take care
   of invoking tools for you.

   However, by manually invoking tools you give yourself the opportunity to add
   controls around tool invocation. For example, you could check shell commands
   before they're executed!

   </Aside>
</Steps>

At this point, the agent will be able to call tools and get a response from the LLM.
However, it isn't exactly a developer yet. We need to add system instructions to turn
our generic agent into a coding agent.

## Add agent instructions

Let's add logic to instruct the agent to behave more like a developer.

<Steps>

1. Add a new file `IAgentInstructions.cs` to the `CodingAgent` project.
1. Add the following using statements to the file:

   ```csharp title="IAgentInstructions.cs"
   using Microsoft.SemanticKernel.ChatCompletion;
   ```

1. Next, add the following code to the file to define the agent instructions:

   ```csharp title="IAgentInstructions.cs"
   namespace CodingAgent;

   public interface IAgentInstructions
   {
      Task InjectAsync(ChatHistory chatHistory);
      void Remove(ChatHistory chatHistory);
   }
   ```

   We add two methods, one to inject the instructions into the chat history and
   one to remove them. You want to inject and remove instructions so that they
   won't end up in storage when you persist the chat history.

   <Aside type="tip">
   Never store your system instructions in storage. If you need to change them at some
   point, you'll have to migrate a lot of data in storage to apply the new instructions.
   </Aside>

1. Then, create a new class `EmbeddedResource.cs` with the following content:

   ```csharp title="EmbeddedResource.cs"
   namespace CodingAgent;

   public static class EmbeddedResource
   {
      public static string Read(string resourceName)
      {
         var assembly = typeof(EmbeddedResource).Assembly;
         
         using var stream = assembly.GetManifestResourceStream(resourceName);
         using var reader = new StreamReader(stream!);

         return reader.ReadToEnd();
      }
   }
   ```

1. After, create a class `AgentInstructions.cs` in the `CodingAgent` project.
1. Add the following using statements to the top of the file:

   ```csharp title="AgentInstructions.cs"
   using Microsoft.SemanticKernel.ChatCompletion;
   ```

1. Next, implement the `IAgentInstructions` interface in the `AgentInstructions`
   class:

   ```csharp title="AgentInstructions.cs"
   namespace CodingAgent;

   public class AgentInstructions: IAgentInstructions
   {
      private readonly Kernel _kernel;

      public AgentInstructions(Kernel kernel)
      {
         _kernel = kernel;
      }

      public async Task InjectAsync(ChatHistory chatHistory)
      {
         var systemPrompt = await ReadSystemInstructionsAsync();
         chatHistory.Insert(0, new ChatMessageContent(AuthorRole.System, systemPrompt));
      }

      public void Remove(ChatHistory chatHistory)
      {
         if (chatHistory.Count > 0 && chatHistory[0].Role == AuthorRole.System)
         {
            chatHistory.RemoveAt(0);
         }
      }
   }
   ```

   The `InjectAsync` method reads the system instructions from an embedded
   resource and adds them as the first message in the chat history with the role
   `System`.

   The `Remove` method checks if the first message in the chat history is a
   system message and removes it if so.

1. Download [AgentSystemInstructions.txt][AGENT_INSTRUCTIONS] and place it in the `Resources`
   folder in the `CodingAgent` project. Make sure to set the file's build action to
   `Embedded Resource` in the file properties.

1. Create the method `ReadSystemInstructionsAsync` in the `AgentInstructions`
   class to read the system instructions from an embedded resource:

   ```csharp title="AgentInstructions.cs" ins={30-38}
   private async Task<string> ReadSystemInstructionsAsync()
   {
      var resourceName = "CodingAgent.Resources.AgentSystemInstructions.txt";
      var instructions = EmbeddedResource.Read(resourceName);

      return await Task.FromResult(instructions);
   }
   ```

1. Modify the `Agent` class so it accepts `IAgentInstructions` in the
   constructor and store them in the `_agentInstructions` variable.

   ```csharp title="Agent.cs" ins={7,10,14} del={9}
   public class Agent
   {
      private const int MaxIterations = 50;
      private ChatHistory _chatHistory;
      private readonly Kernel _kernel;
      private readonly SharedToolsPlugin _sharedToolsPlugin;
      private readonly IAgentInstructions _agentInstructions;

      public Agent(Kernel kernel)
      public Agent(Kernel kernel, IAgentInstructions agentInstructions)
      {
         _chatHistory = new ChatHistory();
         _kernel = kernel;
         _agentInstructions = agentInstructions;
         _sharedToolsPlugin = new SharedToolsPlugin();
         _kernel.Plugins.AddFromObject(_sharedToolsPlugin);
      }
   
      // Rest of the class
   }
   ```

1. Modify the `InvokeAsync` method in the `Agent` class to inject and
   remove the instructions.

   ```csharp title="Agent.cs" ins={6,38}
   public async Task InvokeAsync(string prompt, IAgentCallbacks callbacks)
   {
      var iterations = 0;
      var chatCompletionService = _kernel.GetRequiredService<IChatCompletionService>();

      await _agentInstructions.InjectAsync(_chatHistory);
      _chatHistory.AddUserMessage(prompt);

      while (true)
      {
         iterations++;

         if (iterations > MaxIterations)
         {
               break;
         }

         var promptExecutionSettings = new AzureOpenAIPromptExecutionSettings()
         {
               FunctionChoiceBehavior = FunctionChoiceBehavior.Auto(autoInvoke: false),
         };

         var response = await chatCompletionService
            .GetChatMessageContentAsync(_chatHistory, promptExecutionSettings);

         _chatHistory.Add(response);

         var functionCalls = FunctionCallContent.GetFunctionCalls(response).ToList();

         if (!functionCalls.Any())
         {
            break;
         }

         await HandleFunctionCalls(functionCalls);
      }
   
      _agentInstructions.Remove(_chatHistory);
   }
   ```

1. Modify `Program.cs` to inject the `AgentInstructions` when creating the
   `Agent` instance.

   ```csharp title="Program.cs" ins={19,21} del={20}
   using Microsoft.Extensions.Configuration;
   using Microsoft.SemanticKernel;
   using CodingAgent;
   using Spectre.Console;

   var configuration = new ConfigurationBuilder()
      .AddUserSecrets(typeof(Program).Assembly)
      .AddEnvironmentVariables()
      .Build();

   var kernelBuilder = Kernel.CreateBuilder()
      .AddAzureOpenAIChatCompletion(
         configuration["LanguageModel:DeploymentName"]!,
         configuration["LanguageModel:Endpoint"]!,
         configuration["LanguageModel:ApiKey"]!
      );

   var kernel = kernelBuilder.Build();
   var instructions = new AgentInstructions(kernel);
   var agent = new Agent(kernel);
   var agent = new Agent(kernel, instructions);

   AnsiConsole.Write(new Markup("[green]CODING AGENT[/]\n"));
   AnsiConsole.Write(new Rule());

   while (true)
   {
      var prompt = AnsiConsole.Prompt(new TextPrompt<string>(">"));
      var callbacks = new ConsoleCallbacks();

      // Stop the application when the user enters /exit or /quit.
      if (string.Compare(prompt, "/exit", StringComparison.OrdinalIgnoreCase) == 0 ||
         string.Compare(prompt, "/quit", StringComparison.OrdinalIgnoreCase) == 0)
      {
         break;
      }

      await agent.InvokeAsync(prompt, callbacks);
   }
   ```

</Steps>

Test the agent again, now it should be much better at knowing when to stop and
return the final output.

## Summary

In this lab we create the main agent loop. We added the final output tool to report the 
final outcome of the task and to stop the agent loop. Finally, we added instructions to
the agent to make sure it uses the final output tool correctly.

Please find the final solution for the lab here: [labs/agent-loop/002-main-agent-loop][LAB_SOLUTION_SOURCE].

Right now, the agent doesn't talk too much. We'll fix that in the next module where we
implement callbacks to report progress to the user.

[SK_SERVICES]: https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/
[AGENT_INSTRUCTIONS]: https://raw.githubusercontent.com/wmeints/coding-agent-workshop/refs/heads/main/labs/agent-loop/002-main-agent-loop/CodingAgent/Resources/AgentSystemInstructions.txt
[LAB_START_SOURCE]: https://github.com/wmeints/coding-agent-workshop/tree/main/labs/agent-loop/001-setup-application
[LAB_SOLUTION_SOURCE]: https://github.com/wmeints/coding-agent-workshop/tree/main/labs/agent-loop/002-main-agent-loop